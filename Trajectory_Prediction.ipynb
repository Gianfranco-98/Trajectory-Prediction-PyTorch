{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trajectory-Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learining project\n",
        "\n",
        "\n",
        "*   Gianfranco Di Marco - 1962292\n",
        "*   Giacomo Colizzi Coin - 1794538\n",
        "\n",
        "\n",
        "\\\n",
        "**- Trajectory Prediction -**\n",
        "\n",
        "Is the problem of predicting the short-term (1-3 seconds) and long-term (3-5 seconds) spatial coordinates of various road-agents such as cars, buses, pedestrians, rickshaws, and animals, etc. These road-agents have different dynamic behaviors that may correspond to aggressive or conservative driving styles.\n",
        "\n",
        "**- nuScenes Dataset -**\n",
        "\n",
        "Available at. https://www.nuscenes.org/nuscenes. The nuScenes\n",
        "dataset is a large-scale autonomous driving dataset. The dataset has 3D bounding boxes for 1000 scenes collected in Boston and Singapore. Each scene is 20 seconds long and annotated at 2Hz. This results in a total of 28130 samples for training, 6019 samples for validation and 6008 samples for testing. The dataset has the full autonomous vehicle data suite: 32-beam LiDAR, 6 cameras and radars with complete 360Â° coverage\n",
        "\n",
        "\n",
        "> Holger Caesar and Varun Bankiti and Alex H. Lang and Sourabh Vora and Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and Giancarlo Baldan and Oscar Beijbom: \"*nuScenes: A multimodal dataset for autonomous driving*\", arXiv preprint arXiv:1903.11027, 2019.\n",
        "\n",
        "The most important part of this dataset for our project is the Map Expansion Pack, which simplify the trajectory prediction problem"
      ],
      "metadata": {
        "id": "jYwxiuChyg8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements"
      ],
      "metadata": {
        "id": "Fe3uPCs50bDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "Bt_RVZEdYvzu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4wvD942xC89"
      },
      "outputs": [],
      "source": [
        "!pip install nuscenes-devkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Dataset\n",
        "from nuscenes.nuscenes import NuScenes\n",
        "from nuscenes.prediction import PredictHelper\n",
        "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
        "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
        "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
        "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
        "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
        "from nuscenes.eval.prediction import metrics, data_classes\n",
        "\n",
        "# File system\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "# Generic\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Tuple\n",
        "from abc import abstractmethod\n",
        "import multiprocessing as mp"
      ],
      "metadata": {
        "id": "8tTIrgJRPOjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "u9hftZeWZYE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generic Parameters**"
      ],
      "metadata": {
        "id": "w5fNsDEfaMN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Network parameters\n",
        "PREDICTION_MODEL = 'CoverNet'\n",
        "if PREDICTION_MODEL == 'CoverNet':\n",
        "    BACKBONE_WEIGHTS = 'ImageNet'\n",
        "    BACKBONE_MODEL = 'ResNet50'\n",
        "SHORT_TERM_HORIZON = 3\n",
        "LONG_TERM_HORIZON = 6\n",
        "TRAJ_HORIZON = SHORT_TERM_HORIZON\n",
        "# TODO: ADD OTHER BASELINES\n",
        "\n",
        "# Train parameters\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 8"
      ],
      "metadata": {
        "id": "HfRgW1VNZX-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Parameters**"
      ],
      "metadata": {
        "id": "RXoj0mI-aO--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATAROOT = '/data/sets/nuscenes'\n",
        "PREPROCESSED_FOLDER = 'preprocessed'\n",
        "GT_FOLDER = 'gt'\n",
        "GT_SUFFIX = '-gt'\n",
        "FILENAME_EXT = '.pt'\n",
        "DATASET_VERSION = 'v1.0-trainval'\n",
        "AGGREGATORS = [{'name': \"RowMean\"}]"
      ],
      "metadata": {
        "id": "btLY02YCaO4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "v2Vxmwu00dEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialization**\n",
        "\n",
        "N.B: The download links in function *urllib.request.urlretrieve()* should be replaced periodically because it expires. Steps to download correctly are (on Firefox):\n",
        "\n",
        "\n",
        "1.   Dowload Map Expansion pack (or Trainval metadata) from the website\n",
        "2.   Stop the download\n",
        "3.   Right-click on the file -> copy download link\n",
        "4.   Paste the copied link into the first argument of the urlretrieve function. The second argument is the final name of the file"
      ],
      "metadata": {
        "id": "tfvjWlfxa6Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataset dir\n",
        "!mkdir -p $DATAROOT\n",
        "%cd $DATAROOT\n",
        "\n",
        "# Downloading Map Expansion Pack\n",
        "!mkdir maps\n",
        "%cd maps\n",
        "urllib.request.urlretrieve('https://s3.amazonaws.com/data.nuscenes.org/public/v1.0/nuScenes-map-expansion-v1.3.zip?AWSAccessKeyId=AKIA6RIK4RRMFUKM7AM2&Signature=LEgicAnyLJRiuLeMGIMMy3dWjBI%3D&Expires=1644515526', 'nuScenes-map-expansion-v1.3.zip')\n",
        "!unzip nuScenes-map-expansion-v1.3.zip\n",
        "!rm nuScenes-map-expansion-v1.3.zip\n",
        "\n",
        "# Downloading Trainval Metadata\n",
        "%cd ..\n",
        "!mkdir v1.0-trainval\n",
        "%cd v1.0-trainval\n",
        "urllib.request.urlretrieve('https://s3.amazonaws.com/data.nuscenes.org/public/v1.0/v1.0-trainval_meta.tgz?AWSAccessKeyId=AKIA6RIK4RRMFUKM7AM2&Signature=nLIyCM3W9%2FhYHrXhdVjmSkBbJeQ%3D&Expires=1644515632', 'v1.0-trainval_meta.tgz')\n",
        "!tar -xf v1.0-trainval_meta.tgz\n",
        "!rm v1.0-trainval_meta.tgz\n",
        "!mv v1.0-trainval/* .\n",
        "!rm -r v1.0-trainval\n",
        "!mv maps/* ../maps/"
      ],
      "metadata": {
        "id": "uJ6oVSHz0iCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset definition**"
      ],
      "metadata": {
        "id": "75UDbRMTbA9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrajPredDataset(Dataset):\n",
        "    \"\"\" Trajectory Prediction Dataset\n",
        "\n",
        "    Base Class for Trajectory Prediction Datasets\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, name, data_type, preprocessed, split, \n",
        "                 dataroot, preprocessed_folder, gt_folder,\n",
        "                 filename_ext, gt_suffix, traj_horizon, num_workers):\n",
        "        \"\"\" Dataset Initialization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: the instantiated dataset\n",
        "        name: name of the dataset\n",
        "        data_type: data type of the dataset elements\n",
        "        preprocessed: True if data has already been preprocessed\n",
        "        split: the dataset split ('train', 'train_val', 'val')\n",
        "        dataroot: the root directory of the dataset\n",
        "        preprocessed_folder: the folder containing preprocessed data\n",
        "        gt_folder: the folder containing ground truth data\n",
        "        filename_ext: the extension of the generated filenames\n",
        "        gt_suffix: the suffix added after each GT filename (before ext)\n",
        "        traj_horizon: horizon (in seconds) for the future trajectory\n",
        "        num_workers: num of processes that collect data\n",
        "        \"\"\"\n",
        "        super(TrajPredDataset, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.name = name\n",
        "        self.data_type = data_type\n",
        "        self.preprocessed = preprocessed\n",
        "        self.split = split\n",
        "        self.dataroot = dataroot\n",
        "        self.preprocessed_folder = preprocessed_folder\n",
        "        self.filename_ext = filename_ext\n",
        "        self.gt_suffix = gt_suffix\n",
        "        self.traj_horizon = traj_horizon\n",
        "        self.num_workers = num_workers\n",
        "        self.helper = None\n",
        "        self.tokens = None\n",
        "        self.static_layer_rasterizer = None\n",
        "        self.agent_rasterizer = None\n",
        "        self.input_representation = None\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate_data(self):\n",
        "        \"\"\" Data generation\n",
        "\n",
        "        If self.preprocessed, directly collect data.\n",
        "        Otherwise, generate data without preprocess it.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_raster(self, token):\n",
        "        \"\"\" Convert a token split into a raster\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token: token containing instance token and sample token\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        raster: the raster image\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class nuScenesDataset(TrajPredDataset):\n",
        "    \"\"\" nuScenes Dataset for Trajectory Prediction challenge \"\"\"\n",
        "    def __init__(self, nuscenes, data_type='raster', preprocessed=False, split='train', \n",
        "                 dataroot=DATAROOT, preprocessed_folder=PREPROCESSED_FOLDER, gt_folder=GT_FOLDER,\n",
        "                 filename_ext=FILENAME_EXT, gt_suffix=GT_SUFFIX, traj_horizon=SHORT_TERM_HORIZON,\n",
        "                 aggregators=AGGREGATORS, num_workers=NUM_WORKERS):\n",
        "        \"\"\" nuScenes Dataset Initialization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        nuscenes: the instantiated nuScenes dataset\n",
        "        data_type: data type of the dataset elements\n",
        "        preprocessed: True if data has already been preprocessed\n",
        "        split: the dataset split ('train', 'train_val', 'val')\n",
        "        dataroot: the root directory of the dataset\n",
        "        preprocessed_folder: the folder containing preprocessed data\n",
        "        gt_folder: the folder containing ground truth data\n",
        "        filename_ext: the extension of the generated filenames\n",
        "        gt_suffix: the suffix added after each GT filename (before ext)\n",
        "        traj_horizon: horizon (in seconds) for the future trajectory\n",
        "        aggregators: methods to aggregate many metrics across predictions\n",
        "        num_workers: num of processes that collect data\n",
        "        \"\"\"\n",
        "        super(nuScenesDataset, self).__init__(\n",
        "            nuscenes, 'nuScenes', data_type, preprocessed, split, dataroot, \n",
        "            preprocessed_folder, gt_folder, filename_ext, gt_suffix, traj_horizon, num_workers)\n",
        "        self.helper = PredictHelper(nuscenes)\n",
        "        self.tokens = get_prediction_challenge_split(split, dataroot=self.helper.data.dataroot)\n",
        "        if data_type == 'raster':\n",
        "            self.static_layer_rasterizer = StaticLayerRasterizer(self.helper)\n",
        "            self.agent_rasterizer = AgentBoxesWithFadedHistory(self.helper, seconds_of_history=1)\n",
        "            self.input_representation = InputRepresentation(self.static_layer_rasterizer, self.agent_rasterizer, Rasterizer())\n",
        "        else:   # IDEA: also other type of input data\n",
        "            pass\n",
        "        if not self.preprocessed:\n",
        "            print(\"Preprocessing data ...\")\n",
        "            self.generate_data()\n",
        "        \n",
        "        # metrics\n",
        "        # TODO: check if the outcome is the expected one with [5, 10] \n",
        "        #       (i.e. with [5, 10] a metric returns array with top_5 and top_10 results)\n",
        "        self.aggregators = [metrics.deserialize_aggregator(agg) for agg in aggregators]\n",
        "        self.min_ade = metrics.MinADEK([5, 10], aggregators)\n",
        "        self.miss_rate = metrics.MissRateTopK([5, 10], aggregators)\n",
        "        self.min_fde = metrics.MinFDEK([5, 10], aggregators)\n",
        "        self.offRoadRate = metrics.OffRoadRate(self.helper, self.aggregators)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        complete_tensor = torch.load(\n",
        "            os.path.join(self.dataroot, self.preprocessed_folder, \n",
        "                         self.tokens[idx] + self.filename_ext))\n",
        "        gt_trajectory = torch.load(\n",
        "            os.path.join(self.dataroot, self.preprocessed_folder, self.gt_folder, \n",
        "                         self.tokens[idx] + self.gt_suffix + self.filename_ext))\n",
        "        raster_img, agent_state_vector = self.tensor_io_conversion(None, None, complete_tensor)\n",
        "        return raster_img, agent_state_vector, gt_trajectory\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\" Data generation\n",
        "\n",
        "        If self.preprocessed, directly collect data.\n",
        "        Otherwise, generate data without preprocess it.\n",
        "        \"\"\"\n",
        "        os.mkdir(os.path.join(self.dataroot, self.preprocessed_folder))\n",
        "        if self.data_type == 'raster':\n",
        "            for t in tqdm(self.tokens):\n",
        "                self.generate_raster_data(t)\n",
        "        else:\n",
        "            pass\n",
        "    \n",
        "    def generate_raster_data(self, token):\n",
        "        \"\"\" Generate a raster map and agent state vector from token split \n",
        "\n",
        "        The generated input data consists in a tensor like this:\n",
        "            [raster map | agent state vector]\n",
        "        The generated ground truth data is the future agent trajectory tensor\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token: token containing instance token and sample token\n",
        "        \"\"\"\n",
        "        # Generate and concatenate input tensors\n",
        "        instance_token, sample_token = token.split(\"_\")\n",
        "        raster_img = self.input_representation.make_input_representation(instance_token, sample_token)\n",
        "        raster_tensor = torch.Tensor(raster_img).permute(2, 0, 1) / 255.\n",
        "        agent_state_vector = torch.Tensor([[self.helper.get_velocity_for_agent(instance_token, sample_token),\n",
        "                                            self.helper.get_acceleration_for_agent(instance_token, sample_token),\n",
        "                                            self.helper.get_heading_change_rate_for_agent(instance_token, sample_token)]])\n",
        "        raster_agent_tensor, _ = self.tensor_io_conversion('write', raster_tensor, agent_state_vector)\n",
        "        # IDEA: maybe nan values should be handled\n",
        "\n",
        "        # Generate ground truth\n",
        "        gt_trajectory = torch.Tensor(\n",
        "            self.helper.get_future_for_agent(instance_token, sample_token, \n",
        "                                             seconds=self.traj_horizon, in_agent_frame=True))\n",
        "        \n",
        "        # Save to disk\n",
        "        torch.save(raster_agent_tensor, os.path.join(self.dataroot, self.preprocessed_folder, token + self.filename_ext))\n",
        "        torch.save(gt_trajectory, os.path.join(self.dataroot, self.preprocessed_folder, token + self.gt_suffix + self.filename_ext))\n",
        "\n",
        "    # TODO: check correctness\n",
        "    def compute_metrics(self, tokens, predictions, ground_truth, mode_probabilities, tolerance) -> List[Dict[str, list(float)]]:\n",
        "        \"\"\" Utility eval function to compute dataset metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token: the list of tokens containing instance token and sample token for each prediction\n",
        "        predictions: the predicted trajectories (with Covernet is the fixed set)\n",
        "                     SHAPE: [batch_size, num_modes, n_timesteps, state_dim]\n",
        "        ground_truth: the real trajectory of the agent\n",
        "        mode_probabilities: probabilities of the predicted trajectories\n",
        "                            SHAPE: [batch_size, num_modes]\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        metrics: list of dictionaries of the computed metrics:\n",
        "            - minADE_5: The average of pointwise L2 distances between the predicted trajectory \n",
        "                      and ground truth over the 5 most likely predictions.\n",
        "            - minADE_10: The average of pointwise L2 distances between the predicted trajectory \n",
        "                      and ground truth over the 10 most likely predictions.\n",
        "            - missRateTop_2_5: Proportion of misses relative to the 5 most likely trajectories\n",
        "                            over all agents\n",
        "            - missRateTop_2_10: Proportion of misses relative to the 10 most likely trajectories\n",
        "                            over all agents\n",
        "            - minFDE_1: The final displacement error (FDE) is the L2 distance \n",
        "                      between the final points of the prediction and ground truth, computed\n",
        "                      on the most likely trajectory\n",
        "            - offRoadRate: the fraction of trajectories that are not entirely contained\n",
        "                        in the drivable area of the map.\n",
        "        \"\"\"\n",
        "        metrics = []\n",
        "        for i, token in enumerate(tokens):\n",
        "            i_t, s_t = token.split(\"_\")\n",
        "            prediction = data_classes.Prediction(i_t, s_t, predictions[i], mode_probabilities[i]) \n",
        "            # TODO: check for argument shapes\n",
        "            minADE_5 = self.min_ade(ground_truth[i], prediction, mode_probabilities[i])[0]\n",
        "            minADE_10 = self.min_ade(ground_truth[i], prediction, mode_probabilities[i])[1]\n",
        "            missRateTop_2_5 = self.miss_rate(ground_truth[i], prediction, mode_probabilities[i])[0]\n",
        "            offRoadRate = self.offRoadRate(ground_truth[i], prediction)\n",
        "            metric = {'minADE_5': minADE_5, 'missRateTop_2_5': missRateTop_2_5,\n",
        "                      'minADE_10': minADE_10, 'missRateTop_2_10': missRateTop_2_10,\n",
        "                      'minFDE_1': minFDE_1, 'offRoadRate': offRoadRate}\n",
        "            metrics.append(metric)\n",
        "        return metrics\n",
        "    \n",
        "    @staticmethod\n",
        "    def tensor_io_conversion(mode, big_t=None, small_t=None, complete_t=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\" Utility IO function to concatenate tensors of different shape\n",
        "\n",
        "        Normally used to concatenate (or separate) raster map and agent state vector in order to speed up IO\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode: 'write' (concatenate) or 'read' (separate)\n",
        "        big_t: the bigger tensor (None if we are going to separate tensors)\n",
        "        small_t: the smaller tensor (None if we are going to separate tensors)\n",
        "        complete_t: the concatenated tensor (None if we are going to concatenate tensors)\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        out1: big tensor (mode == 'read') or complete tensor (mode == 'write')\n",
        "        out2: small tensor (mode == 'read') or empty tensor (mode == 'write') \n",
        "        \"\"\"\n",
        "        out1, out2 = None, None\n",
        "        if mode == 'write':    # concatenate\n",
        "            if big_t is None or small_t is None:\n",
        "                raise ValueError(\"Wrong argument: 'big_t' and 'small_t' cannot be None\")\n",
        "            small_t = small_t.permute(1, 0).unsqueeze(2)\n",
        "            small_t = small_t.expand(-1, -1, big_t.shape[-1])\n",
        "            out1 = torch.cat((big_t, small_t), dim=1)\n",
        "            out2 = torch.empty(small_t.shape)\n",
        "        elif mode == 'read':    # separate\n",
        "            if complete_t is None:\n",
        "                raise ValueError(\"Wrong argument: 'complete_t' cannot be None\")\n",
        "            out1 = complete_t[..., -1, -1].unsqueeze(0)\n",
        "            out2 = complete_t[..., :-1, :]\n",
        "        else:\n",
        "            raise ValueError(\"Wrong argument 'mode'; available 'read' or 'write'\")        \n",
        "        return out1, out2"
      ],
      "metadata": {
        "id": "mHqZde4mbDkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code testing"
      ],
      "metadata": {
        "id": "TTM0gLeFVR4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nusc = NuScenes(version=DATASET_VERSION, dataroot=DATAROOT, verbose=True)\n",
        "dataset = nuScenesDataset(nusc)\n",
        "train_dataloader = DataLoader(dataset, BATCH_SIZE, True, num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "S5uPp-rLC7qd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}