{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYwxiuChyg8u"
      },
      "source": [
        "## Deep Learining project\n",
        "\n",
        "\n",
        "*   Gianfranco Di Marco - 1962292\n",
        "*   Giacomo Colizzi Coin - 1794538\n",
        "\n",
        "\n",
        "\\\n",
        "**- Trajectory Prediction -**\n",
        "\n",
        "Is the problem of predicting the short-term (1-3 seconds) and long-term (3-5 seconds) spatial coordinates of various road-agents such as cars, buses, pedestrians, rickshaws, and animals, etc. These road-agents have different dynamic behaviors that may correspond to aggressive or conservative driving styles.\n",
        "\n",
        "**- nuScenes Dataset -**\n",
        "\n",
        "Available at. https://www.nuscenes.org/nuscenes. The nuScenes\n",
        "dataset is a large-scale autonomous driving dataset. The dataset has 3D bounding boxes for 1000 scenes collected in Boston and Singapore. Each scene is 20 seconds long and annotated at 2Hz. This results in a total of 28130 samples for training, 6019 samples for validation and 6008 samples for testing. The dataset has the full autonomous vehicle data suite: 32-beam LiDAR, 6 cameras and radars with complete 360Â° coverage\n",
        "\n",
        "\n",
        "> Holger Caesar and Varun Bankiti and Alex H. Lang and Sourabh Vora and Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and Giancarlo Baldan and Oscar Beijbom: \"*nuScenes: A multimodal dataset for autonomous driving*\", arXiv preprint arXiv:1903.11027, 2019.\n",
        "\n",
        "The most important part of this dataset for our project is the Map Expansion Pack, which simplify the trajectory prediction problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe3uPCs50bDU"
      },
      "source": [
        "## Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VbP-XZY0xvv"
      },
      "source": [
        "**Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ-Kwgkp0xog",
        "outputId": "9b1ef494-7f58-4b72-c94b-816216eadd9b"
      },
      "outputs": [],
      "source": [
        "# Necessary since Google Colab supports only Python 3.7\n",
        "# -> some libraries can be different from local and Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    from google.colab import drive\n",
        "    ENVIRONMENT = 'colab'\n",
        "    %pip install tf-estimator-nightly==2.8.0.dev2021122109\n",
        "    %pip install folium==0.2.1\n",
        "except:\n",
        "    ENVIRONMENT = 'local'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt_RVZEdYvzu"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y4wvD942xC89",
        "outputId": "313777e0-4580-461d-eedd-778f9eda7b0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nuscenes-devkit in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (1.1.9)\n",
            "Requirement already satisfied: cachetools in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (5.0.0)\n",
            "Requirement already satisfied: fire in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (0.4.0)\n",
            "Requirement already satisfied: opencv-python in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (4.5.5.64)\n",
            "Requirement already satisfied: descartes in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (1.0.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (2.0.4)\n",
            "Requirement already satisfied: Shapely in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (1.8.1.post1)\n",
            "Requirement already satisfied: jupyter in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (3.5.1)\n",
            "Requirement already satisfied: numpy in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (1.21.2)\n",
            "Requirement already satisfied: tqdm in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (4.64.0)\n",
            "Requirement already satisfied: scipy in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (1.8.0)\n",
            "Requirement already satisfied: pyquaternion>=0.9.5 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (0.9.9)\n",
            "Requirement already satisfied: Pillow>6.2.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nuscenes-devkit) (9.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from matplotlib->nuscenes-devkit) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from matplotlib->nuscenes-devkit) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from matplotlib->nuscenes-devkit) (4.31.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from matplotlib->nuscenes-devkit) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from matplotlib->nuscenes-devkit) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from matplotlib->nuscenes-devkit) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->nuscenes-devkit) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from fire->nuscenes-devkit) (1.1.0)\n",
            "Requirement already satisfied: ipykernel in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter->nuscenes-devkit) (6.12.1)\n",
            "Requirement already satisfied: nbconvert in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter->nuscenes-devkit) (6.4.5)\n",
            "Requirement already satisfied: ipywidgets in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter->nuscenes-devkit) (7.7.0)\n",
            "Requirement already satisfied: jupyter-console in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter->nuscenes-devkit) (6.4.3)\n",
            "Requirement already satisfied: qtconsole in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter->nuscenes-devkit) (5.3.0)\n",
            "Requirement already satisfied: notebook in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter->nuscenes-devkit) (6.4.10)\n",
            "Requirement already satisfied: debugpy>=1.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (1.5.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (7.0.6)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (8.2.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (6.1)\n",
            "Requirement already satisfied: psutil in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (5.8.0)\n",
            "Requirement already satisfied: nest-asyncio in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (1.5.5)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (0.1.3)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipykernel->jupyter->nuscenes-devkit) (5.1.1)\n",
            "Requirement already satisfied: decorator in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (5.1.1)\n",
            "Requirement already satisfied: stack-data in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.2.0)\n",
            "Requirement already satisfied: backcall in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (58.0.4)\n",
            "Requirement already satisfied: pickleshare in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.7.5)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (2.11.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.18.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (3.0.29)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.8.3)\n",
            "Requirement already satisfied: entrypoints in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->nuscenes-devkit) (0.4)\n",
            "Requirement already satisfied: pyzmq>=13 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->nuscenes-devkit) (19.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter->nuscenes-devkit) (4.9.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipywidgets->jupyter->nuscenes-devkit) (1.1.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipywidgets->jupyter->nuscenes-devkit) (0.2.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipywidgets->jupyter->nuscenes-devkit) (5.3.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from ipywidgets->jupyter->nuscenes-devkit) (3.6.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nuscenes-devkit) (4.4.0)\n",
            "Requirement already satisfied: fastjsonschema in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nuscenes-devkit) (2.15.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nuscenes-devkit) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nuscenes-devkit) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nuscenes-devkit) (5.6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter->nuscenes-devkit) (3.8.0)\n",
            "Requirement already satisfied: prometheus-client in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from notebook->jupyter->nuscenes-devkit) (0.13.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from notebook->jupyter->nuscenes-devkit) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from notebook->jupyter->nuscenes-devkit) (0.13.3)\n",
            "Requirement already satisfied: jinja2 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from notebook->jupyter->nuscenes-devkit) (3.1.1)\n",
            "Requirement already satisfied: argon2-cffi in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from notebook->jupyter->nuscenes-devkit) (21.3.0)\n",
            "Requirement already satisfied: defusedxml in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (0.7.1)\n",
            "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (0.5.13)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (2.1.1)\n",
            "Requirement already satisfied: bleach in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (4.1.0)\n",
            "Requirement already satisfied: testpath in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (1.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (0.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from nbconvert->jupyter->nuscenes-devkit) (4.10.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->nuscenes-devkit) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->nuscenes-devkit) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->nuscenes-devkit) (2.21)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter->nuscenes-devkit) (2.3.1)\n",
            "Requirement already satisfied: webencodings in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->nuscenes-devkit) (0.5.1)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from qtconsole->jupyter->nuscenes-devkit) (2.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from scikit-learn->nuscenes-devkit) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from scikit-learn->nuscenes-devkit) (1.1.0)\n",
            "Requirement already satisfied: asttokens in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.2.2)\n",
            "Requirement already satisfied: executing in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->nuscenes-devkit) (0.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pytorch-lightning in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (1.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (0.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (1.21.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (4.64.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (2022.3.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (4.1.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (2.8.0)\n",
            "Requirement already satisfied: torch>=1.8.* in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (1.11.0)\n",
            "Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pytorch-lightning) (0.3.2)\n",
            "Requirement already satisfied: aiohttp in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n",
            "Requirement already satisfied: requests in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.27.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.6.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.20.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.1.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.44.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (58.0.4)\n",
            "Requirement already satisfied: six in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (5.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.9)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install nuscenes-devkit\n",
        "%pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8tTIrgJRPOjo"
      },
      "outputs": [],
      "source": [
        "# Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet50\n",
        "import pytorch_lightning as pl\n",
        "from torchmetrics import functional\n",
        "\n",
        "# Math\n",
        "import numpy as np\n",
        "\n",
        "# Dataset\n",
        "from nuscenes.nuscenes import NuScenes\n",
        "from nuscenes.prediction import PredictHelper\n",
        "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
        "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
        "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
        "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
        "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
        "from nuscenes.eval.prediction import metrics, data_classes\n",
        "\n",
        "# File system\n",
        "import os\n",
        "import pickle\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# Generic\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from typing import List, Dict, Tuple\n",
        "from abc import abstractmethod\n",
        "import multiprocessing as mp\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9hftZeWZYE3"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5fNsDEfaMN3"
      },
      "source": [
        "**Generic Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HfRgW1VNZX-D"
      },
      "outputs": [],
      "source": [
        "# Environment-dependent parameters\n",
        "if ENVIRONMENT == 'colab':\n",
        "    ROOT = '/content/drive/MyDrive/DL/Trajectory-Prediction-PyTorch/'\n",
        "    MAX_NUM_WORKERS = 2\n",
        "    MAX_BATCH_SIZE = 8\n",
        "    PROGRESS_BAR_REFRESH_RATE = 20\n",
        "elif ENVIRONMENT == 'local':\n",
        "    ROOT = os.getcwd() + '/'\n",
        "    MAX_NUM_WORKERS = 4\n",
        "    MAX_BATCH_SIZE = 8\n",
        "    PROGRESS_BAR_REFRESH_RATE = 10\n",
        "else:\n",
        "    raise ValueError(\"Wrong 'environment' value\")\n",
        "\n",
        "# Train parameters\n",
        "# TODO: find the best batch size possible\n",
        "# TODO: define correct number of epoches\n",
        "BATCH_SIZE = MAX_BATCH_SIZE\n",
        "NUM_WORKERS = MAX_NUM_WORKERS\n",
        "LEARNING_RATE = 1e-4\n",
        "TRAIN_EPOCHES = 20 \n",
        "PLOT_PERIOD = 4023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rFOOPSWgiOG"
      },
      "source": [
        "**Network Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iS5EccU9giHb"
      },
      "outputs": [],
      "source": [
        "# TODO: add other baselines\n",
        "PREDICTION_MODEL = 'CoverNet'\n",
        "if PREDICTION_MODEL == 'CoverNet':\n",
        "    # - Architecture parameters\n",
        "    BACKBONE_WEIGHTS = 'ImageNet'\n",
        "    BACKBONE_MODEL = 'ResNet18'\n",
        "    K_SIZE = 20000\n",
        "    # - Trajectory parameters\n",
        "    AGENT_HISTORY = 1\n",
        "    SHORT_TERM_HORIZON = 3\n",
        "    LONG_TERM_HORIZON = 6\n",
        "    TRAJ_HORIZON = SHORT_TERM_HORIZON\n",
        "    TRAJ_LINK = 'https://www.nuscenes.org/public/nuscenes-prediction-challenge-trajectory-sets.zip'\n",
        "    TRAJ_DIR = ROOT + 'trajectory_sets'\n",
        "    EPSILON = 2   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXoj0mI-aO--"
      },
      "source": [
        "**Dataset Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "btLY02YCaO4Y"
      },
      "outputs": [],
      "source": [
        "# Organization parameters\n",
        "PREPARE_DATASET = False\n",
        "PREPROCESSED = True\n",
        "# TODO: set automatically this need\n",
        "HELPER_NEEDED = False\n",
        "\n",
        "# File system parameters\n",
        "PL_SEED = 42\n",
        "DATAROOT = ROOT + 'data/sets/nuscenes'\n",
        "PREPROCESSED_FOLDER = 'preprocessed'\n",
        "GT_SUFFIX = '-gt'\n",
        "FILENAME_EXT = '.pt'\n",
        "DATASET_VERSION = 'v1.0-trainval'\n",
        "AGGREGATORS = [{'name': \"RowMean\"}]\n",
        "\n",
        "# Other parameters\n",
        "SAMPLES_PER_SECOND = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Vxmwu00dEd"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfvjWlfxa6Gy"
      },
      "source": [
        "**Initialization**\n",
        "\n",
        "N.B: The download links in function *urllib.request.urlretrieve()* should be replaced periodically because it expires. Steps to download correctly are (on Firefox):\n",
        "\n",
        "\n",
        "1.   Dowload Map Expansion pack (or Trainval metadata) from the website\n",
        "2.   Stop the download\n",
        "3.   Right-click on the file -> copy download link\n",
        "4.   Paste the copied link into the first argument of the urlretrieve function. The second argument is the final name of the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHQCO92UCoCD",
        "outputId": "8419e9f9-7ee9-4f94-dda6-0d75c7120761"
      },
      "outputs": [],
      "source": [
        "# Drive initialization\n",
        "if ENVIRONMENT == 'colab':\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uJ6oVSHz0iCf"
      },
      "outputs": [],
      "source": [
        "if PREPARE_DATASET:\n",
        "\n",
        "    # Creating dataset dir\n",
        "    !mkdir -p $DATAROOT\n",
        "    %cd $DATAROOT\n",
        "\n",
        "    # Downloading Map Expansion Pack\n",
        "    !mkdir maps\n",
        "    %cp nuScenes-map-expansion-v1.3.zip maps/nuScenes-map-expansion-v1.3.zip\n",
        "    %cd maps\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/data.nuscenes.org/public/v1.0/nuScenes-map-expansion-v1.3.zip?AWSAccessKeyId=AKIA6RIK4RRMFUKM7AM2&Signature=T2qxIyqETqvrZxVg3NOy4E73I4o%3D&Expires=1649583583', 'nuScenes-map-expansion-v1.3.zip')\n",
        "    !unzip nuScenes-map-expansion-v1.3.zip\n",
        "    !rm nuScenes-map-expansion-v1.3.zip\n",
        "\n",
        "    # Downloading Trainval Metadata\n",
        "    %cd ..\n",
        "    !mkdir v1.0-trainval\n",
        "    %cp v1.0-trainval_meta.tgz v1.0-trainval/v1.0-trainval_meta.tgz\n",
        "    %cd v1.0-trainval\n",
        "    urllib.request.urlretrieve('https://s3.amazonaws.com/data.nuscenes.org/public/v1.0/v1.0-trainval_meta.tgz?AWSAccessKeyId=AKIA6RIK4RRMFUKM7AM2&Signature=azZWQs26iYyS7tPEoMitolBXDs0%3D&Expires=1649583610', 'v1.0-trainval_meta.tgz')\n",
        "    !tar -xf v1.0-trainval_meta.tgz\n",
        "    !rm v1.0-trainval_meta.tgz\n",
        "    !mv v1.0-trainval/* .\n",
        "    !rm -r v1.0-trainval\n",
        "    !mv maps/* ../maps/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75UDbRMTbA9V"
      },
      "source": [
        "**Dataset definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mHqZde4mbDkC"
      },
      "outputs": [],
      "source": [
        "class TrajPredDataset(Dataset):\n",
        "    \"\"\" Trajectory Prediction Dataset\n",
        "\n",
        "    Base Class for Trajectory Prediction Datasets\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, name, data_type, preprocessed, split,\n",
        "                 dataroot, preprocessed_folder,\n",
        "                 filename_ext, gt_suffix, traj_horizon, num_workers):\n",
        "        \"\"\" Dataset Initialization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: the instantiated dataset\n",
        "        name: name of the dataset\n",
        "        data_type: data type of the dataset elements\n",
        "        preprocessed: True if data has already been preprocessed\n",
        "        split: the dataset split ('train', 'train_val', 'val')\n",
        "        dataroot: the root directory of the dataset\n",
        "        preprocessed_folder: the folder containing preprocessed data\n",
        "        filename_ext: the extension of the generated filenames\n",
        "        gt_suffix: the suffix added after each GT filename (before ext)\n",
        "        traj_horizon: horizon (in seconds) for the future trajectory\n",
        "        num_workers: num of processes that collect data\n",
        "        \"\"\"\n",
        "        super(TrajPredDataset, self).__init__()\n",
        "        self.dataset = dataset\n",
        "        self.name = name\n",
        "        self.data_type = data_type\n",
        "        self.preprocessed = preprocessed\n",
        "        self.split = split\n",
        "        self.dataroot = dataroot\n",
        "        self.preprocessed_folder = preprocessed_folder\n",
        "        self.filename_ext = filename_ext\n",
        "        self.gt_suffix = gt_suffix\n",
        "        self.traj_horizon = traj_horizon\n",
        "        self.num_workers = num_workers\n",
        "        self.helper = None\n",
        "        self.tokens = None\n",
        "        self.static_layer_rasterizer = None\n",
        "        self.agent_rasterizer = None\n",
        "        self.input_representation = None\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate_data(self):\n",
        "        \"\"\" Data generation\n",
        "\n",
        "        If self.preprocessed, directly collect data.\n",
        "        Otherwise, generate data without preprocess it.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_raster(self, token):\n",
        "        \"\"\" Convert a token split into a raster\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token: token containing instance token and sample token\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        raster: the raster image\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class nuScenesDataset(TrajPredDataset):\n",
        "    \"\"\" nuScenes Dataset for Trajectory Prediction challenge \"\"\"\n",
        "    def __init__(self, helper, data_type='raster', preprocessed=False, split='train',\n",
        "                 dataroot=DATAROOT, preprocessed_folder=PREPROCESSED_FOLDER,\n",
        "                 filename_ext=FILENAME_EXT, gt_suffix=GT_SUFFIX, \n",
        "                 traj_horizon=TRAJ_HORIZON, samples_per_second=SAMPLES_PER_SECOND,\n",
        "                 agent_history=AGENT_HISTORY, aggregators=AGGREGATORS, num_workers=NUM_WORKERS):\n",
        "        \"\"\" nuScenes Dataset Initialization\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        helper: the helper of the instantiated nuScenes dataset (None if not needed)\n",
        "        data_type: data type of the dataset elements\n",
        "        preprocessed: True if data has already been preprocessed\n",
        "        split: the dataset split ('train', 'train_val', 'val')\n",
        "        dataroot: the root directory of the dataset\n",
        "        preprocessed_folder: the folder containing preprocessed data\n",
        "        filename_ext: the extension of the generated filenames\n",
        "        gt_suffix: the suffix added after each GT filename (before ext)\n",
        "        traj_horizon: horizon (in seconds) for the future trajectory\n",
        "        samples_per_second: sampling frequency (in Hertz)\n",
        "        agent_history: the seconds of considered agent history\n",
        "        aggregators: methods to aggregate many metrics across predictions\n",
        "        num_workers: num of processes that collect data\n",
        "        \"\"\"\n",
        "        super(nuScenesDataset, self).__init__(\n",
        "            None, 'nuScenes', data_type, preprocessed, split, dataroot,\n",
        "            preprocessed_folder, filename_ext, gt_suffix, traj_horizon, num_workers)\n",
        "        self.helper = helper\n",
        "        self.tokens = get_prediction_challenge_split(\n",
        "            split, dataroot=dataroot)\n",
        "        self.samples_per_second = samples_per_second\n",
        "        if data_type == 'raster':\n",
        "            if helper is not None:\n",
        "                self.static_layer_rasterizer = StaticLayerRasterizer(self.helper)\n",
        "                self.agent_rasterizer = AgentBoxesWithFadedHistory(\n",
        "                    self.helper, seconds_of_history=AGENT_HISTORY)\n",
        "                self.input_representation = InputRepresentation(\n",
        "                    self.static_layer_rasterizer, self.agent_rasterizer, Rasterizer())\n",
        "            else:\n",
        "                self.static_layer_rasterizer = None\n",
        "                self.agent_rasterizer = None\n",
        "                self.input_representation = None\n",
        "        else:   # IDEA: also other type of input data\n",
        "            pass\n",
        "        if not self.preprocessed:\n",
        "            print(\"Preprocessing data ...\")\n",
        "            self.generate_data()\n",
        "\n",
        "        # metrics\n",
        "        # TODO: check if the outcome is the expected one with [5, 10]\n",
        "        #       (i.e. with [5, 10] a metric returns array with top_5 and top_10 results)\n",
        "        self.aggregators = \\\n",
        "            [metrics.deserialize_aggregator(agg) for agg in aggregators]\n",
        "        self.min_ade = metrics.MinADEK([5, 10], aggregators)\n",
        "        self.miss_rate = metrics.MissRateTopK([5, 10], aggregators)\n",
        "        self.min_fde = metrics.MinFDEK([1], aggregators)\n",
        "        if helper is not None:\n",
        "            # FIXME: instantiating offRoadRate class makes RAM explode\n",
        "            #self.offRoadRate = metrics.OffRoadRate(self.helper, self.aggregators)\n",
        "            pass\n",
        "        else:\n",
        "            self.offRoadRate = None\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.tokens)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        subfolder = f'batch_{idx//128}'\n",
        "        complete_tensor = torch.load(\n",
        "            os.path.join(self.dataroot, self.preprocessed_folder, subfolder,\n",
        "                         self.tokens[idx] + self.filename_ext))\n",
        "        gt_trajectory = torch.load(\n",
        "            os.path.join(self.dataroot, self.preprocessed_folder, subfolder,\n",
        "                         self.tokens[idx] + self.gt_suffix + self.filename_ext))\n",
        "        # TODO: check correctness\n",
        "        # IDEA: add also loop for < 5 shape\n",
        "        if gt_trajectory.shape[0] < self.samples_per_second * self.traj_horizon:\n",
        "            gt_trajectory = torch.concat((gt_trajectory, gt_trajectory[-1].unsqueeze(0)))\n",
        "        agent_state_vector, raster_img = self.tensor_io_conversion(\n",
        "            \"read\", None, None, complete_tensor)\n",
        "        return agent_state_vector, raster_img, gt_trajectory\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\" Data generation\n",
        "\n",
        "        If self.preprocessed, directly collect data.\n",
        "        Otherwise, generate data without preprocess it.\n",
        "        \"\"\"\n",
        "        if not self.preprocessed_folder in os.listdir(self.dataroot):\n",
        "            os.mkdir(os.path.join(self.dataroot, self.preprocessed_folder))\n",
        "        # variable useful to restore interrupted preprocessing\n",
        "        preprocessed_batches = os.listdir(os.path.join(self.dataroot, self.preprocessed_folder))\n",
        "        already_preproc = \\\n",
        "            len([f for f in preprocessed_batches\n",
        "                 if os.path.isfile(os.path.join(self.dataroot, self.preprocessed_folder, f))])\n",
        "\n",
        "        # create subfolders\n",
        "        if len(preprocessed_batches) == 0:\n",
        "            n_subfolders = len(self.tokens) // 128 + int(len(self.tokens) % 128 != 0)\n",
        "            for i in range(n_subfolders):\n",
        "                subfolder = 'batch_' + str(i)\n",
        "                os.mkdir(os.path.join(self.dataroot, self.preprocessed_folder, subfolder))\n",
        "\n",
        "        # generate data\n",
        "        if self.data_type == 'raster':\n",
        "            for i, t in enumerate(tqdm(self.tokens)):\n",
        "                subfolder = f'batch_{i//128}'\n",
        "                if i >= int(already_preproc/2):\n",
        "                    self.generate_raster_data(t, subfolder)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def generate_raster_data(self, token, subfolder):\n",
        "        \"\"\" Generate a raster map and agent state vector from token split \n",
        "\n",
        "        The generated input data consists in a tensor like this:\n",
        "            [raster map | agent state vector]\n",
        "        The generated ground truth data is the future agent trajectory tensor\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token: token containing instance token and sample token\n",
        "        subfolder: the data is divided into subfolders in order to avoid Drive timeouts;\n",
        "            this parameter tells which is the actual subfolder towhere place data\n",
        "        \"\"\"\n",
        "        # Generate and concatenate input tensors\n",
        "        instance_token, sample_token = token.split(\"_\")\n",
        "        raster_img = self.input_representation.make_input_representation(\n",
        "            instance_token, sample_token)\n",
        "        raster_tensor = torch.Tensor(raster_img).permute(2, 0, 1) / 255.\n",
        "        agent_state_vector = torch.Tensor(\n",
        "            [[self.helper.get_velocity_for_agent(instance_token, sample_token),\n",
        "              self.helper.get_acceleration_for_agent(instance_token, sample_token),\n",
        "              self.helper.get_heading_change_rate_for_agent(instance_token, sample_token)]])\n",
        "        raster_agent_tensor, _ = \\\n",
        "            self.tensor_io_conversion('write', raster_tensor, agent_state_vector)\n",
        "        # IDEA: maybe nan values should be handled\n",
        "\n",
        "        # Generate ground truth\n",
        "        # TODO: generate gt trajectories also for traj_horizon = 6s\n",
        "        gt_trajectory = torch.Tensor(\n",
        "            self.helper.get_future_for_agent(instance_token, sample_token,\n",
        "                                             seconds=self.traj_horizon, in_agent_frame=True))\n",
        "\n",
        "        # Save to disk\n",
        "        torch.save(raster_agent_tensor, os.path.join(self.dataroot,\n",
        "                   self.preprocessed_folder, subfolder, token + self.filename_ext))\n",
        "        torch.save(gt_trajectory, os.path.join(\n",
        "            self.dataroot, self.preprocessed_folder, subfolder, token + self.gt_suffix + self.filename_ext))\n",
        "\n",
        "    # TODO: check correctness\n",
        "    def compute_metrics(self, tokens, predictions, ground_truth, mode_probabilities, tolerance) -> List[Dict[str, List[float]]]:\n",
        "        \"\"\" Utility eval function to compute dataset metrics\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        token: the list of tokens containing instance token and sample token for each prediction\n",
        "        predictions: the predicted trajectories (with Covernet is the fixed set)\n",
        "                     SHAPE: [batch_size, num_modes, n_timesteps, state_dim]\n",
        "        ground_truth: the real trajectory of the agent\n",
        "        mode_probabilities: probabilities of the predicted trajectories\n",
        "                            SHAPE: [batch_size, num_modes]\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        metric_list: list of dictionaries of the computed metrics:\n",
        "            - minADE_5: The average of pointwise L2 distances between the predicted trajectory \n",
        "                      and ground truth over the 5 most likely predictions.\n",
        "            - minADE_10: The average of pointwise L2 distances between the predicted trajectory \n",
        "                      and ground truth over the 10 most likely predictions.\n",
        "            - missRateTop_2_5: Proportion of misses relative to the 5 most likely trajectories\n",
        "                            over all agents\n",
        "            - missRateTop_2_10: Proportion of misses relative to the 10 most likely trajectories\n",
        "                            over all agents\n",
        "            - minFDE_1: The final displacement error (FDE) is the L2 distance \n",
        "                      between the final points of the prediction and ground truth, computed\n",
        "                      on the most likely trajectory\n",
        "            - offRoadRate: the fraction of trajectories that are not entirely contained\n",
        "                        in the drivable area of the map.\n",
        "        \"\"\"\n",
        "        metric_list = []\n",
        "        for i, token in enumerate(tokens):\n",
        "            i_t, s_t = token.split(\"_\")\n",
        "            prediction = data_classes.Prediction(i_t, s_t, predictions[i], mode_probabilities[i]) \n",
        "            # TODO: check for argument shapes\n",
        "            minADE_5 = self.min_ade(ground_truth[i], prediction, mode_probabilities[i])[0]\n",
        "            minADE_10 = self.min_ade(ground_truth[i], prediction, mode_probabilities[i])[1]\n",
        "            missRateTop_2_5 = self.miss_rate(ground_truth[i], prediction, mode_probabilities[i])[0]\n",
        "            missRateTop_2_10 = self.miss_rate(ground_truth[i], prediction, mode_probabilities[i])[1]\n",
        "            minFDE_1 = self.min_fde(ground_truth[i], predictions[i])\n",
        "            offRoadRate = self.offRoadRate(ground_truth[i], prediction)\n",
        "            metric = {'minADE_5': minADE_5, 'missRateTop_2_5': missRateTop_2_5,\n",
        "                      'minADE_10': minADE_10, 'missRateTop_2_10': missRateTop_2_10,\n",
        "                      'minFDE_1': minFDE_1, 'offRoadRate': offRoadRate}\n",
        "            metric_list.append(metric)\n",
        "        return metric_list\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_io_conversion(mode, big_t=None, small_t=None, complete_t=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\" Utility IO function to concatenate tensors of different shape\n",
        "\n",
        "        Normally used to concatenate (or separate) raster map and agent state vector in order to speed up IO\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode: 'write' (concatenate) or 'read' (separate)\n",
        "        big_t: the bigger tensor (None if we are going to separate tensors)\n",
        "        small_t: the smaller tensor (None if we are going to separate tensors)\n",
        "        complete_t: the concatenated tensor (None if we are going to concatenate tensors)\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        out1: big tensor (mode == 'read') or complete tensor (mode == 'write')\n",
        "        out2: small tensor (mode == 'read') or empty tensor (mode == 'write') \n",
        "        \"\"\"\n",
        "        out1, out2 = None, None\n",
        "        if mode == 'write':    # concatenate\n",
        "            if big_t is None or small_t is None:\n",
        "                raise ValueError(\"Wrong argument: 'big_t' and 'small_t' cannot be None\")\n",
        "            small_t = small_t.permute(1, 0).unsqueeze(2)\n",
        "            small_t = small_t.expand(-1, -1, big_t.shape[-1])\n",
        "            out1 = torch.cat((big_t, small_t), dim=1)\n",
        "            out2 = torch.empty(small_t.shape)\n",
        "        elif mode == 'read':    # separate\n",
        "            if complete_t is None:\n",
        "                raise ValueError(\"Wrong argument: 'complete_t' cannot be None\")\n",
        "            out1 = complete_t[..., -1, -1].unsqueeze(0)\n",
        "            out2 = complete_t[..., :-1, :]\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Wrong argument 'mode'; available 'read' or 'write'\")\n",
        "        return out1, out2\n",
        "\n",
        "class nuScenesDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, nuscenes, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
        "        super(nuScenesDataModule, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.nuscenes = nuscenes\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # TODO: define also test and validation dataset\n",
        "        # IDEA: maybe there can be space problems with splitted datasets\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            self.nusc_train = self.nuscenes\n",
        "            self.nusc_val = self.nuscenes\n",
        "\n",
        "        if stage == 'test' or stage is None:\n",
        "            self.nusc_test = self.nuscenes\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.nusc_train, self.batch_size, \n",
        "                          shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.nusc_val, self.batch_size, \n",
        "                          shuffle=False, num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.nusc_test, self.batch_size, \n",
        "                          shuffle=False, num_workers=self.num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isw61mh9-IZD"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eetqgcIS-d7W"
      },
      "source": [
        "**ResNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WVXnujwk-dz-"
      },
      "outputs": [],
      "source": [
        "class Block(pl.LightningModule):\n",
        "  \"\"\"The Residual block of ResNet.\"\"\"\n",
        "  def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n",
        "        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n",
        "        super(Block, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        if self.num_layers > 34:\n",
        "            self.expansion = 4\n",
        "        else:\n",
        "            self.expansion = 1\n",
        "        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        if self.num_layers > 34:\n",
        "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        else:\n",
        "            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n",
        "            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "\n",
        "  def forward(self, x):\n",
        "        identity = x\n",
        "        if self.num_layers > 34:\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(pl.LightningModule):\n",
        "    def __init__(self, num_layers, image_channels):\n",
        "        assert num_layers in [18, 34, 50, 101, 152], print(\"Number of layers has to be 18, 34, 50, 101, or 152 \")\n",
        "        super(ResNet, self).__init__()\n",
        "        if num_layers < 50:\n",
        "            self.expansion = 1\n",
        "        else:\n",
        "            self.expansion = 4\n",
        "        if num_layers == 18:\n",
        "            layers = [2, 2, 2, 2]\n",
        "        elif num_layers == 34 or num_layers == 50:\n",
        "            layers = [3, 4, 6, 3]\n",
        "        elif num_layers == 101:\n",
        "            layers = [3, 4, 23, 3]\n",
        "        else:\n",
        "            layers = [3, 8, 36, 3]\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # ResNetLayers\n",
        "        self.layer1 = self.make_layers(num_layers, layers[0], intermediate_channels=64, stride=1)\n",
        "        self.layer2 = self.make_layers(num_layers, layers[1], intermediate_channels=128, stride=2)\n",
        "        self.layer3 = self.make_layers(num_layers, layers[2], intermediate_channels=256, stride=2)\n",
        "        self.layer4 = self.make_layers(num_layers, layers[3], intermediate_channels=512, stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        # x = x.reshape(x.shape[0], -1)\n",
        "        return x\n",
        "\n",
        "    def make_layers(self, num_layers, num_residual_blocks, intermediate_channels, stride):\n",
        "        layers = []\n",
        "\n",
        "        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n",
        "                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n",
        "        layers.append(Block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n",
        "        self.in_channels = intermediate_channels * self.expansion # 256\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(Block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n",
        "        return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blyIPM3r-TgN"
      },
      "source": [
        "**Covernet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g_OGzCNn-TZA"
      },
      "outputs": [],
      "source": [
        "class CoverNet(pl.LightningModule):\n",
        "    def __init__(self, K_size, epsilon, traj_link, traj_dir, device, \n",
        "                 lr=LEARNING_RATE, plot_period=PLOT_PERIOD):\n",
        "        super().__init__()\n",
        "        self.convModel = resnet50(pretrained=True)\n",
        "        self.activation = {}\n",
        "        def get_activation(name):\n",
        "            def hook(model, input, output):\n",
        "                self.activation[name] = output#.detach()\n",
        "            return hook\n",
        "        self.convModel.layer4.register_forward_hook(get_activation('layer4'))\n",
        "        self.trajectories = prepare_trajectories(epsilon, traj_link, traj_dir)\n",
        "        self.fc1 = nn.Linear(2051, 4096)\n",
        "        self.fc2 = nn.Linear(4096, self.trajectories.size()[0])\n",
        "        self.plot_period = plot_period\n",
        "        self.tgt_device = device\n",
        "        self.loss_arr = []\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, x):\n",
        "        img, state = x\n",
        "        # TODO: check if ResNet should learn\n",
        "        #with torch.no_grad():\n",
        "        #    self.convModel(img)\n",
        "        #    resnet_output = torch.flatten(self.convModel.avgpool(self.activation['layer4']),start_dim=1)\n",
        "        self.convModel(img)\n",
        "        resnet_output = torch.flatten(self.convModel.avgpool(self.activation['layer4']),start_dim=1)\n",
        "        x = torch.cat([resnet_output, state], 1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Prepare data and labels\n",
        "        x_state, x_img, gt = batch\n",
        "        x_state = torch.flatten(x_state, 0, 1)\n",
        "        reduced_traj = self.trajectories[:, :SAMPLES_PER_SECOND*TRAJ_HORIZON]\n",
        "        with torch.no_grad():\n",
        "            y = get_positives(reduced_traj, gt.detach().to('cpu'))\n",
        "        # Inference\n",
        "        traj_logits = self((x_img, x_state))\n",
        "        # Compute loss\n",
        "        y_hat = reduced_traj[traj_logits.argmax(dim=1)]\n",
        "        # TODO: check if it's needed to send to CUDA device\n",
        "        y = y.to(self.tgt_device)\n",
        "        y_hat = y_hat.to(self.tgt_device)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        # TODO: check if it's correct\n",
        "        loss.requires_grad = True\n",
        "\n",
        "        # Plot training trend\n",
        "        self.loss_arr.append(loss.detach().to('cpu'))\n",
        "        if (batch_idx % self.plot_period == 0) and batch_idx > 0:\n",
        "            plot_train_data(list(range(batch_idx+1)), self.loss_arr)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # TODO: check also for other optimizers\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "\n",
        "def get_positives(trajectories, ground_truth):\n",
        "    \"\"\" Get positive samples wrt the actual GT\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    trajectories: the pre-generated set of trajectories\n",
        "    ground_truth: the future trajectory for the agent\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    positive_traj: as defined in the original CoverNet paper, \n",
        "        'positive samples determined by the element in the trajectory set\n",
        "        closest to the actual ground truth in minimum average \n",
        "        of point-wise Euclidean distances'\n",
        "    \"\"\"\n",
        "    euclidean_dist = torch.stack([torch.pow(torch.sub(trajectories, gt), 2) \n",
        "                                  for gt in ground_truth]).sum(dim=3).sqrt() \n",
        "    mean_euclidean_dist = euclidean_dist.mean(dim=2)\n",
        "    positive_traj = trajectories[mean_euclidean_dist.argmin(dim=1)]\n",
        "    return positive_traj\n",
        "\n",
        "def prepare_trajectories(epsilon, download_link, directory):\n",
        "    \"\"\" Function to download and extract trajectory sets for CoverNet \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    epsilon: value (in meters) relative to the space coverage\n",
        "    download_link: link from which to download trajectory sets\n",
        "    directory: directory where to download trajectory sets\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    trajectories: tensor of the trajectory set for the specified epsilon\n",
        "    \"\"\"\n",
        "    # 1. Download and extract trajectories\n",
        "    filename_zip = os.path.join(directory,\n",
        "        'nuscenes-prediction-challenge-trajectory-sets.zip')\n",
        "    filename = filename_zip[:-4]\n",
        "    if (not os.path.isdir(filename) or any(e not in os.listdir(os.path.join(filename))\n",
        "            for e in ['epsilon_2.pkl', 'epsilon_4.pkl', 'epsilon_8.pkl'])):\n",
        "        print(\"Downloading trajectories ...\")\n",
        "        urllib.request.urlretrieve(download_link, filename_zip)\n",
        "        with zipfile.ZipFile(filename_zip, 'r') as archive:\n",
        "            archive.extractall()\n",
        "        os.remove(filename_zip)\n",
        "\n",
        "    # 2. Generate trajectories\n",
        "    traj_set_path = os.path.join(filename, 'epsilon_' + str(epsilon) + '.pkl')\n",
        "    trajectories = pickle.load(open(traj_set_path, 'rb'))\n",
        "    return torch.Tensor(trajectories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train Utilities**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_train_data(iterations, losses):\n",
        "    \"\"\"\n",
        "    Plot a graph with the training trend\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    iterations: array with actual iterations for each iteration\n",
        "    losses: array of loss values\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "\n",
        "    plt.title('Training Process')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Value')\n",
        "    l, = plt.plot(iterations, losses, c='blue')\n",
        "\n",
        "    plt.legend(handles=[l], labels=['CoverNet Loss'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLIMN2u3AkE3"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3DiJYZKAuhZ"
      },
      "source": [
        "**Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875,
          "referenced_widgets": [
            "fa8c974115444ba7a12c90c8a8d87516",
            "c30dc3da002f4e7c82a8ac5a68a5ffb5",
            "455963cc7508493e8ebfae33153fecd5",
            "5e92b547a76b4553b5db52dc0ed2cfb5",
            "4bac5714ea1e4ccb9e01324e21141988",
            "f39c30c9d8b14c1e94903cefe2a39729",
            "016a7c13e8c04e839b62f41277bbef0b",
            "b5b47bdfa1a54ecfa4bf83af9cc5a0a8",
            "917719585d5c4cde891fa9d24c1c452d",
            "8e30339b13f5456ca91124789f04c3c1",
            "eb628135b5d249d287fbfec0e012c810"
          ]
        },
        "id": "lsGEsxRVAuLI",
        "outputId": "eaa7d5e4-4c49-4640-8ae1-31b03b4d504a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "nuScenes Helper initialization ...\n",
            "nuScenes Helper initialization done in 0.003463 s\n",
            "\n",
            "\n",
            "Dataset and Data Module initialization ...\n",
            "Dataset and Data Module initialization done in 0.026974 s\n",
            "\n",
            "\n",
            "CoverNet model initialization ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=10)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  rank_zero_deprecation(\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CoverNet model intialization done in 0.749465 s\n",
            "\n",
            "\n",
            "Trainer initialization ...\n",
            "Trainer intialization done in 0.004486 s\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---------- Dataset initialization ---------- #\n",
        "# Initialize nuScenes helper\n",
        "# FIXME: Pickle Problem (Ran out of input) in Colab\n",
        "print(\"\\nnuScenes Helper initialization ...\")\n",
        "start_time = time.time()\n",
        "pl.seed_everything(PL_SEED)\n",
        "if ENVIRONMENT == 'local':\n",
        "    if PREPARE_DATASET:\n",
        "        nusc = NuScenes(version=DATASET_VERSION, dataroot=DATAROOT, verbose=True)\n",
        "        with open(os.path.join(ROOT, 'nuscenes_checkpoint'+FILENAME_EXT), 'wb') as f:\n",
        "            pickle.dump(nusc, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    elif not 'nusc' in locals():\n",
        "        if HELPER_NEEDED:\n",
        "            with open(os.path.join(ROOT, 'nuscenes_checkpoint'+FILENAME_EXT), 'rb') as f:\n",
        "                nusc = pickle.load(f)\n",
        "elif ENVIRONMENT == 'colab':\n",
        "    if PREPARE_DATASET or HELPER_NEEDED:\n",
        "        nusc = NuScenes(version=DATASET_VERSION, dataroot=DATAROOT, verbose=True)\n",
        "helper = PredictHelper(nusc) if HELPER_NEEDED else None\n",
        "print(\"nuScenes Helper initialization done in %f s\\n\" % (time.time() - start_time))\n",
        "\n",
        "# Initialize dataset and data module\n",
        "print(\"\\nDataset and Data Module initialization ...\")\n",
        "start_time = time.time()\n",
        "nusc_dataset = nuScenesDataset(helper, preprocessed=PREPROCESSED)\n",
        "nusc_dm = nuScenesDataModule(nusc_dataset)\n",
        "print(\"Dataset and Data Module initialization done in %f s\\n\" % (time.time() - start_time)) \n",
        "\n",
        "# ---------- Network initialization ---------- #\n",
        "print(\"\\nCoverNet model initialization ...\")\n",
        "start_time = time.time()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CoverNet(K_SIZE, EPSILON, TRAJ_LINK, TRAJ_DIR, device)\n",
        "print(\"CoverNet model intialization done in %f s\\n\" % (time.time() - start_time))\n",
        "\n",
        "# ---------- Training initialization ---------- #\n",
        "# TODO: check if GPU definition is correct\n",
        "print(\"\\nTrainer initialization ...\")\n",
        "start_time = time.time()\n",
        "GPUS = min(1, torch.cuda.device_count())\n",
        "trainer = pl.Trainer(progress_bar_refresh_rate=PROGRESS_BAR_REFRESH_RATE, \n",
        "                     gpus=GPUS, max_epochs=TRAIN_EPOCHES)\n",
        "print(\"Trainer intialization done in %f s\\n\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y1_nMkNAw9A"
      },
      "source": [
        "**Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "93e2a2bf0452441ebab39d237c4181eb",
            "f013776f9b704391aff767c307a62cd8",
            "2fea7a80fe1241519ba0dd6a221f8703",
            "6c12ccb59ad945d3818e9f0087161e83",
            "140606ee7e89497fa83119ff988c223f",
            "9abf84629b8144a7a13eb0c5e6559eb6",
            "396e2e66ddce4c5aa88898c1b4bf29b0",
            "fb33fcf4191e4a60b78ffd71f067f29a",
            "6eceb15e9c8c43a2a7da57049071f180",
            "4b524f2d58934f3f811240dd2d8ea621",
            "c8fecad947374e859766802f0fdac494"
          ]
        },
        "id": "caBfMgTGAw1Y",
        "outputId": "7a84e58a-7233-4344-9410-771a2fd00791"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:131: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type   | Params\n",
            "-------------------------------------\n",
            "0 | convModel | ResNet | 25.6 M\n",
            "1 | fc1       | Linear | 8.4 M \n",
            "2 | fc2       | Linear | 9.0 M \n",
            "-------------------------------------\n",
            "43.0 M    Trainable params\n",
            "0         Non-trainable params\n",
            "43.0 M    Total params\n",
            "172.000   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23e8d25c70154af6856bafef5ae8e115",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gianfranco/anaconda3/envs/torch2022/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:727: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(model, nusc_dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTM0gLeFVR4J"
      },
      "source": [
        "## Code testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7y8IMO_-479"
      },
      "source": [
        "**Dataset testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5uPp-rLC7qd"
      },
      "outputs": [],
      "source": [
        "# Initialize nuScenes\n",
        "# FIXME: Pickle Problem (Ran out of input) in Colab\n",
        "if ENVIRONMENT == 'local':\n",
        "    if PREPARE_DATASET:\n",
        "        nusc = NuScenes(version=DATASET_VERSION, dataroot=DATAROOT, verbose=True)\n",
        "        with open(os.path.join(ROOT, 'nuscenes_checkpoint'+FILENAME_EXT), 'wb') as f:\n",
        "            pickle.dump(nusc, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    elif not 'nusc' in locals():\n",
        "        with open(os.path.join(ROOT, 'nuscenes_checkpoint'+FILENAME_EXT), 'rb') as f:\n",
        "            nusc = pickle.load(f)\n",
        "elif ENVIRONMENT == 'colab':\n",
        "    nusc = NuScenes(version=DATASET_VERSION, dataroot=DATAROOT, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTJuTk-A8jLI"
      },
      "outputs": [],
      "source": [
        "helper = PredictHelper(nusc)\n",
        "dataset = nuScenesDataset(helper, preprocessed=PREPROCESSED)\n",
        "train_dataloader = DataLoader(dataset, BATCH_SIZE, True, num_workers=NUM_WORKERS)\n",
        "train_generator = iter(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MORS9Jw6MCE"
      },
      "outputs": [],
      "source": [
        "# Useful to check ideal number of workers and batch size\n",
        "# N.B: the first batch will take a long\n",
        "x = time.time()\n",
        "try:\n",
        "    state, img, gt = next(train_generator)\n",
        "except StopIteration:\n",
        "    train_generator = iter(train_dataloader)\n",
        "    state, img, gt = next(train_generator)\n",
        "print(time.time() - x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR8Wpz-n8jLJ"
      },
      "outputs": [],
      "source": [
        "state, img, gt = dataset[np.random.randint(len(dataset))]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()\n",
        "print(\"State input size:\", state.shape)\n",
        "print(\"Ground truth size:\", gt.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQWIhylL-_Po"
      },
      "source": [
        "**Network testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTWbk_F38jLS"
      },
      "outputs": [],
      "source": [
        "test_states, test_imgs, test_gts = next(train_generator)\n",
        "test_states = torch.flatten(test_states, 0, 1)\n",
        "\n",
        "print(test_imgs.size())\n",
        "print(test_states.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePJM5C7J8jLT"
      },
      "outputs": [],
      "source": [
        "# Prediction\n",
        "model = CoverNet(K_SIZE, EPSILON, TRAJ_LINK, TRAJ_DIR, device='cuda:0')\n",
        "traj_logits = model((test_imgs, test_states))\n",
        "\n",
        "# Output 5 and 10 most likely trajectories for this batch\n",
        "top_5_trajectories = model.trajectories[traj_logits.argsort(descending=True)[:5]]\n",
        "top_10_trajectories = model.trajectories[traj_logits.argsort(descending=True)[:10]]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Trajectory_Prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "016a7c13e8c04e839b62f41277bbef0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140606ee7e89497fa83119ff988c223f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2fea7a80fe1241519ba0dd6a221f8703": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb33fcf4191e4a60b78ffd71f067f29a",
            "max": 4024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6eceb15e9c8c43a2a7da57049071f180",
            "value": 80
          }
        },
        "396e2e66ddce4c5aa88898c1b4bf29b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "455963cc7508493e8ebfae33153fecd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5b47bdfa1a54ecfa4bf83af9cc5a0a8",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_917719585d5c4cde891fa9d24c1c452d",
            "value": 102530333
          }
        },
        "4b524f2d58934f3f811240dd2d8ea621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bac5714ea1e4ccb9e01324e21141988": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e92b547a76b4553b5db52dc0ed2cfb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e30339b13f5456ca91124789f04c3c1",
            "placeholder": "â",
            "style": "IPY_MODEL_eb628135b5d249d287fbfec0e012c810",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 126MB/s]"
          }
        },
        "6c12ccb59ad945d3818e9f0087161e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b524f2d58934f3f811240dd2d8ea621",
            "placeholder": "â",
            "style": "IPY_MODEL_c8fecad947374e859766802f0fdac494",
            "value": " 80/4024 [06:06&lt;5:01:13,  4.58s/it, loss=189, v_num=0]"
          }
        },
        "6eceb15e9c8c43a2a7da57049071f180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e30339b13f5456ca91124789f04c3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917719585d5c4cde891fa9d24c1c452d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93e2a2bf0452441ebab39d237c4181eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f013776f9b704391aff767c307a62cd8",
              "IPY_MODEL_2fea7a80fe1241519ba0dd6a221f8703",
              "IPY_MODEL_6c12ccb59ad945d3818e9f0087161e83"
            ],
            "layout": "IPY_MODEL_140606ee7e89497fa83119ff988c223f"
          }
        },
        "9abf84629b8144a7a13eb0c5e6559eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b47bdfa1a54ecfa4bf83af9cc5a0a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c30dc3da002f4e7c82a8ac5a68a5ffb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39c30c9d8b14c1e94903cefe2a39729",
            "placeholder": "â",
            "style": "IPY_MODEL_016a7c13e8c04e839b62f41277bbef0b",
            "value": "100%"
          }
        },
        "c8fecad947374e859766802f0fdac494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb628135b5d249d287fbfec0e012c810": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f013776f9b704391aff767c307a62cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9abf84629b8144a7a13eb0c5e6559eb6",
            "placeholder": "â",
            "style": "IPY_MODEL_396e2e66ddce4c5aa88898c1b4bf29b0",
            "value": "Epoch 0:   2%"
          }
        },
        "f39c30c9d8b14c1e94903cefe2a39729": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa8c974115444ba7a12c90c8a8d87516": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c30dc3da002f4e7c82a8ac5a68a5ffb5",
              "IPY_MODEL_455963cc7508493e8ebfae33153fecd5",
              "IPY_MODEL_5e92b547a76b4553b5db52dc0ed2cfb5"
            ],
            "layout": "IPY_MODEL_4bac5714ea1e4ccb9e01324e21141988"
          }
        },
        "fb33fcf4191e4a60b78ffd71f067f29a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
